{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics\n",
    "\n",
    "## add names here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The aim of this project is to use the IMDB Dataset: (Link) and use data such as actors, director, genre, isAdult and runtime to predict how well a movie will perform. We use the boxoffice and userrating as measures of performance. We will train our model with 80% of the data and test it on the remaining 20%. We will also give our predicitons for upcoming movies that do not have any ratings/boxoffice yet.\n",
    "\n",
    "### Our hypothesis is that actors & director will positively influence the performance while the variable runtime will negatively influence it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing"
   ]
  },
  {
   "source": [
    "## title basics "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/flo/anaconda3/envs/datascience/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "(7869186, 9)\n",
      "(189861, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      tconst titleType        primaryTitle       originalTitle  isAdult  \\\n",
       "0  tt0011216     movie      Spanish Fiesta   La fête espagnole        0   \n",
       "1  tt0016906     movie          Frivolinas          Frivolinas        0   \n",
       "2  tt0019996     movie             Hongxia             Hongxia        0   \n",
       "3  tt0035423     movie      Kate & Leopold      Kate & Leopold        0   \n",
       "4  tt0036177     movie  Muhomatsu no issho  Muhomatsu no issho        0   \n",
       "\n",
       "   startYear  runtimeMinutes                  genres  \n",
       "0       2019              67                   Drama  \n",
       "1       2014              80          Comedy,Musical  \n",
       "2       2011              94                  Action  \n",
       "3       2001             118  Comedy,Fantasy,Romance  \n",
       "4       2008             100        Action,Adventure  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tconst</th>\n      <th>titleType</th>\n      <th>primaryTitle</th>\n      <th>originalTitle</th>\n      <th>isAdult</th>\n      <th>startYear</th>\n      <th>runtimeMinutes</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0011216</td>\n      <td>movie</td>\n      <td>Spanish Fiesta</td>\n      <td>La fête espagnole</td>\n      <td>0</td>\n      <td>2019</td>\n      <td>67</td>\n      <td>Drama</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0016906</td>\n      <td>movie</td>\n      <td>Frivolinas</td>\n      <td>Frivolinas</td>\n      <td>0</td>\n      <td>2014</td>\n      <td>80</td>\n      <td>Comedy,Musical</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0019996</td>\n      <td>movie</td>\n      <td>Hongxia</td>\n      <td>Hongxia</td>\n      <td>0</td>\n      <td>2011</td>\n      <td>94</td>\n      <td>Action</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0035423</td>\n      <td>movie</td>\n      <td>Kate &amp; Leopold</td>\n      <td>Kate &amp; Leopold</td>\n      <td>0</td>\n      <td>2001</td>\n      <td>118</td>\n      <td>Comedy,Fantasy,Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0036177</td>\n      <td>movie</td>\n      <td>Muhomatsu no issho</td>\n      <td>Muhomatsu no issho</td>\n      <td>0</td>\n      <td>2008</td>\n      <td>100</td>\n      <td>Action,Adventure</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/title.basics.tsv\",sep=\"\\t\")\n",
    "# Select all non tv Series\n",
    "df = df[(df['endYear']=='\\\\N')]\n",
    "df.drop([\"endYear\"],axis=1,inplace=True)\n",
    "df = df[(df['titleType']==\"movie\")]\n",
    "# replace all \\N with NAN and subsequently drop them\n",
    "df.replace(\"\\\\N\",np.nan,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "# Convert data types to int where feasible\n",
    "df['startYear'] = df['startYear'].astype(int)\n",
    "df['isAdult'] = df['isAdult'].astype(int)\n",
    "df['runtimeMinutes'] = df['runtimeMinutes'].astype(int)\n",
    "\n",
    "df = df[(df['startYear']>=2000) & (df['startYear']<=2020)]\n",
    "\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.to_csv(\"data/title.basics_preprocessed.csv\",index=False)\n",
    "df"
   ]
  },
  {
   "source": [
    "## Box Office Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/boxOffice.csv\")\n",
    "df.dropna(how=\"all\",subset=[\"domestic\",\"international\",\"worldwide\"],inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.to_csv(\"data/boxOffice_preprocessed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"filename\")\n",
    "\n",
    "\n",
    "# extract train and test variables\n",
    "data = df.to_numpy()\n",
    "X = df.loc[:, df.columns != ''].to_numpy()   # enter column name of test variable\n",
    "y = np.log(df['']).to_numpy()                # enter column name of test variable\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Steps performed\n",
    "\n",
    "### dropping columns, imputing missing values, categorical datapoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold to decrease potential overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_validation(X,y,model):\n",
    "    start = time.time()\n",
    "    kf = KFold(n_splits=5,shuffle=True, random_state=69420) \n",
    "    mses = []\n",
    "    models = []\n",
    "    count = 0\n",
    "    for trainIndices,testIndices in kf.split(X):\n",
    "        print(f\"iteration: {count}\")\n",
    "        Xtrain,Xval = X[trainIndices,:],X[testIndices,:]\n",
    "        ytrain,yval = y[trainIndices],y[testIndices]\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        yhat = model.predict(Xval)\n",
    "        mse = np.sum(np.square(yval-yhat))/yval.size # mean squared error\n",
    "        mses.append(mse)\n",
    "        models.append(model)\n",
    "        count+=1\n",
    "    print(f\"time used (seconds): {time.time()-start}\")\n",
    "    return mses, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardise to make data more comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1c2940b2ed4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstandardise_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xtest, ytrain,ytest = train_test_split(X,y,shuffle=True,train_size=0.8)\n",
    "\n",
    "def standardise_data(X):\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_std = (X-mean)/std\n",
    "    return X_std, mean, std\n",
    "\n",
    "#kf = KFold(n_splits=1,shuffle=True, random_state=69420) \n",
    "\n",
    "Xtrain_std, X_train_mean, X_train_std_div = standardise_data(Xtrain)\n",
    "Xtest_std = (Xtest-X_train_mean)/X_train_std_div\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c7d38ea9cf44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "mses,models = kfold_validation(Xtrain,ytrain,model)\n",
    "yhat=models[np.argmin(mses)].predict(Xtest)\n",
    "np.mean(np.square(yhat-ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-25150f82213d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "model = RandomForestRegressor()\n",
    "mses,models = kfold_validation(Xtrain,ytrain,model)\n",
    "yhat=models[np.argmin(mses)].predict(Xtest)\n",
    "np.mean(np.square(yhat-ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0298d0c028ebfbad302948d29e6e2a6b25739bae27aa80b20798b13185bce1864",
   "display_name": "Python 3.8.8 64-bit ('datascience': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}