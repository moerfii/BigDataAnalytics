{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics\n",
    "\n",
    "## add names here:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The aim of this project is to use the IMDB Dataset: (Link) and use data such as actors, director, genre, isAdult and runtime to predict how well a movie will perform. We use the boxoffice and userrating as measures of performance. We will train our model with 80% of the data and test it on the remaining 20%. We will also give our predicitons for upcoming movies that do not have any ratings/boxoffice yet.\n",
    "\n",
    "### Our hypothesis is that actors & director will positively influence the performance while the variable runtime will negatively influence it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.linear_model import Ridge,LinearRegression,Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "source": [
    "## title basics "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading data\n",
      "/home/flo/anaconda3/envs/datascience/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "(7869186, 9)\n",
      "Dropping TV-series\n",
      "dropping endYear column\n",
      "dropping tv episodes\n",
      "replacing \\N\n",
      "dropping NAN's\n",
      "converting startYear, isAdult and runtimeMinutes to int\n",
      "selecting correct time frame\n",
      "(1232056, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "   isAdult  startYear  runtimeMinutes                    genres  \n",
       "0        0       1894               1         Documentary,Short  \n",
       "1        0       1892               5           Animation,Short  \n",
       "2        0       1892               4  Animation,Comedy,Romance  \n",
       "3        0       1892              12           Animation,Short  \n",
       "4        0       1893               1              Comedy,Short  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tconst</th>\n      <th>titleType</th>\n      <th>primaryTitle</th>\n      <th>originalTitle</th>\n      <th>isAdult</th>\n      <th>startYear</th>\n      <th>runtimeMinutes</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0000001</td>\n      <td>short</td>\n      <td>Carmencita</td>\n      <td>Carmencita</td>\n      <td>0</td>\n      <td>1894</td>\n      <td>1</td>\n      <td>Documentary,Short</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0000002</td>\n      <td>short</td>\n      <td>Le clown et ses chiens</td>\n      <td>Le clown et ses chiens</td>\n      <td>0</td>\n      <td>1892</td>\n      <td>5</td>\n      <td>Animation,Short</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0000003</td>\n      <td>short</td>\n      <td>Pauvre Pierrot</td>\n      <td>Pauvre Pierrot</td>\n      <td>0</td>\n      <td>1892</td>\n      <td>4</td>\n      <td>Animation,Comedy,Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0000004</td>\n      <td>short</td>\n      <td>Un bon bock</td>\n      <td>Un bon bock</td>\n      <td>0</td>\n      <td>1892</td>\n      <td>12</td>\n      <td>Animation,Short</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0000005</td>\n      <td>short</td>\n      <td>Blacksmith Scene</td>\n      <td>Blacksmith Scene</td>\n      <td>0</td>\n      <td>1893</td>\n      <td>1</td>\n      <td>Comedy,Short</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "print(\"loading data\")\n",
    "df = pd.read_csv(\"data/title.basics.tsv\",sep=\"\\t\")\n",
    "print(df.shape)\n",
    "print(\"Dropping TV-series\")\n",
    "df = df[(df['endYear']=='\\\\N')]\n",
    "print(\"dropping endYear column\")\n",
    "df.drop([\"endYear\"],axis=1,inplace=True)\n",
    "# specific TV episodes we want to drop\n",
    "print(\"dropping tv episodes\")\n",
    "#episodes_indices = np.where(df['titleType']==\"tvEpisode\")\n",
    "#df.drop(episodes_indices[0],axis=0,inplace=True)\n",
    "df = df[(df['titleType']!=\"tvEpisode\")]\n",
    "#replace \\N with NAN\n",
    "print(\"replacing \\\\N\")\n",
    "df.replace(\"\\\\N\",np.nan,inplace=True)\n",
    "#drop NAN\n",
    "print(\"dropping NAN's\")\n",
    "df.dropna(inplace=True)\n",
    "#converting startYear to int\n",
    "print(\"converting startYear, isAdult and runtimeMinutes to int\")\n",
    "df['startYear'] = df['startYear'].astype(int)\n",
    "df['isAdult'] = df['isAdult'].astype(int)\n",
    "df['runtimeMinutes'] = df['runtimeMinutes'].astype(int)\n",
    "\n",
    "#select correct time frame\n",
    "print(\"selecting correct time frame\")\n",
    "df = df[(df['startYear']>=2000) & df['startYear']<=2020]\n",
    "\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.to_csv(\"data/title.basics_preprocessed.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"filename\")\n",
    "\n",
    "\n",
    "# extract train and test variables\n",
    "data = df.to_numpy()\n",
    "X = df.loc[:, df.columns != ''].to_numpy()   # enter column name of test variable\n",
    "y = np.log(df['']).to_numpy()                # enter column name of test variable\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Steps performed\n",
    "\n",
    "### dropping columns, imputing missing values, categorical datapoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold to decrease potential overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_validation(X,y,model):\n",
    "    start = time.time()\n",
    "    kf = KFold(n_splits=5,shuffle=True, random_state=69420) \n",
    "    mses = []\n",
    "    models = []\n",
    "    count = 0\n",
    "    for trainIndices,testIndices in kf.split(X):\n",
    "        print(f\"iteration: {count}\")\n",
    "        Xtrain,Xval = X[trainIndices,:],X[testIndices,:]\n",
    "        ytrain,yval = y[trainIndices],y[testIndices]\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        yhat = model.predict(Xval)\n",
    "        mse = np.sum(np.square(yval-yhat))/yval.size # mean squared error\n",
    "        mses.append(mse)\n",
    "        models.append(model)\n",
    "        count+=1\n",
    "    print(f\"time used (seconds): {time.time()-start}\")\n",
    "    return mses, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardise to make data more comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1c2940b2ed4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstandardise_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xtest, ytrain,ytest = train_test_split(X,y,shuffle=True,train_size=0.8)\n",
    "\n",
    "def standardise_data(X):\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X_std = (X-mean)/std\n",
    "    return X_std, mean, std\n",
    "\n",
    "#kf = KFold(n_splits=1,shuffle=True, random_state=69420) \n",
    "\n",
    "Xtrain_std, X_train_mean, X_train_std_div = standardise_data(Xtrain)\n",
    "Xtest_std = (Xtest-X_train_mean)/X_train_std_div\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c7d38ea9cf44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "mses,models = kfold_validation(Xtrain,ytrain,model)\n",
    "yhat=models[np.argmin(mses)].predict(Xtest)\n",
    "np.mean(np.square(yhat-ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-25150f82213d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "model = RandomForestRegressor()\n",
    "mses,models = kfold_validation(Xtrain,ytrain,model)\n",
    "yhat=models[np.argmin(mses)].predict(Xtest)\n",
    "np.mean(np.square(yhat-ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0298d0c028ebfbad302948d29e6e2a6b25739bae27aa80b20798b13185bce1864",
   "display_name": "Python 3.8.8 64-bit ('datascience': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}